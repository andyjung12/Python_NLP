{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널 추가\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "train_images, test_images = train_images/255.0, test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature learning\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten()) # 순서대로 1열로 만들기\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1452 - accuracy: 0.9552\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0468 - accuracy: 0.9856\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0332 - accuracy: 0.9893\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0196 - accuracy: 0.9941\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0116 - accuracy: 0.9963\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0101 - accuracy: 0.99670s - loss: 0.0101 - accuracy: \n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0087 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fee2aac0c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0397 - accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904000163078308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "conv1 = layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu)(inputs)\n",
    "pool1 = layers.MaxPooling2D(padding='same')(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu)(pool1)\n",
    "pool2 = layers.MaxPooling2D(padding='same')(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), padding='same', activation=tf.nn.relu)(pool2)\n",
    "pool3 = layers.MaxPooling2D(padding='same')(conv3)\n",
    "pool3_flat = layers.Flatten()(pool3)\n",
    "dense4 = layers.Dense(256, activation=tf.nn.relu)(pool3_flat)\n",
    "drop4 = layers.Dropout(rate=0.2)(dense4)\n",
    "logits = layers.Dense(units=10, activation='softmax')(drop4)\n",
    "model = Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1251 - accuracy: 0.9603\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0411 - accuracy: 0.9872\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 74s 40ms/step - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0227 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0186 - accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0153 - accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.99 - 69s 37ms/step - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0083 - accuracy: 0.9973\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0259 - accuracy: 0.9926\n",
      "0.9926000237464905\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,701,130\n",
      "Trainable params: 1,701,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Class 함수 사용하여 학습\n",
    "class MNISTModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu)\n",
    "        self.pool1 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv2 = layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu)\n",
    "        self.pool2 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv3 = layers.Conv2D(128, (3, 3), padding='same', activation=tf.nn.relu)\n",
    "        self.conv3_flat = layers.Flatten()\n",
    "        self.dense4 = layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.drop4 = layers.Dropout(rate=0.2)\n",
    "        self.dense5 = layers.Dense(units=10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.conv3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        net = self.dense5(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "model = MNISTModel()\n",
    "model(layers.Input(shape=(28, 28, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.1142 - accuracy: 0.9640\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0410 - accuracy: 0.9870\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0291 - accuracy: 0.9909\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0215 - accuracy: 0.9934\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0170 - accuracy: 0.9947\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0140 - accuracy: 0.9956\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 78s 41ms/step - loss: 0.0100 - accuracy: 0.99700s - loss: 0.0101 \n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 76s 40ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 76s 41ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0055 - accuracy: 0.9984\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0484 - accuracy: 0.9928\n",
      "0.9927999973297119\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=20)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0065 - accuracy: 0.9984\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 76s 40ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 5.2540e-04 - accuracy: 0.99980s - loss: 5.2946e-04 \n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 3.7275e-04 - accuracy: 0.9999\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 84s 45ms/step - loss: 1.6208e-04 - accuracy: 0.99991s - l\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 4.3526e-05 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 2.1599e-05 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 1.1304e-05 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 9.0697e-06 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 6.6697e-06 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 8.1467e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 65s 34ms/step - loss: 8.2566e-06 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 3.1302e-06 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 3.3412e-06 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 2.0625e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 8.9717e-06 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 63s 33ms/step - loss: 9.0775e-06 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 2.2701e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 1.5844e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 9.3276e-06 - accuracy: 1.0000\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0537 - accuracy: 0.9939 0s - loss: 0.0502 - accuracy:  - ETA: 0s - loss: 0.0477 - accu\n",
      "0.9939000010490417\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=20)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split를 사용하여 학습\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, \n",
    "                                                                        test_labels, \n",
    "                                                                        test_size=0.2,\n",
    "                                                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_images), len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0229 - val_accuracy: 0.9933\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0263 - val_accuracy: 0.9945\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 72s 39ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0292 - val_accuracy: 0.9935\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 3.5066e-04 - accuracy: 0.9999 - val_loss: 0.0290 - val_accuracy: 0.9944\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 1.9715e-04 - accuracy: 0.9999 - val_loss: 0.0307 - val_accuracy: 0.9941\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 1.2481e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9944\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 6.5692e-05 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9945\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 2.9859e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9945\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 68s 37ms/step - loss: 4.0624e-05 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9944\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 1.9188e-05 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9944\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 1.2113e-04 - accuracy: 0.9999 - val_loss: 0.0331 - val_accuracy: 0.9942\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 72s 39ms/step - loss: 3.5586e-05 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9942\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 3.5971e-05 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9942\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 2.2001e-05 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9942\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 2.7773e-05 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9942\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 1.7467e-05 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9942\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 2.8805e-05 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9942\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 3.8299e-05 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9942\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0220 - accuracy: 0.9965\n",
      "0.9965000152587891\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(train_images, train_labels, validation_data = (valid_images, valid_labels), epochs=20)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss & accuracy 시각화\n",
    "\n",
    "def display(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='valid_loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train_accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='valid_accuracy')\n",
    "    acc_ax.set_xlabel('epoch')\n",
    "    acc_ax.set_ylabel('accuracy')\n",
    "    acc_ax.legend(loc='upper right', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split를 사용하여 학습 (batch_size & 더 많은 epoch)\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                 batch_size=200)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelCheckpoint & EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model의 weight 값 중간 저장(ModelCheckpoint)\n",
    "# 개선되지 않는 학습에 대한 조기 종료(EarlyStopping) \n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = 'C:/Users/andyj/abangers/멀티캠퍼스(데이터분석)/자연어처리'\n",
    "model_file_path = f'{MODEL_SAVE_FOLDER_PATH}/mnist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_file_path,\n",
    "                                monitor='val_accuracy',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True)\n",
    "cb_early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                 batch_size=200\n",
    "                 callbacks=[cb_checkpoint, cb_early_stopping])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장했던 Model의 weight 가져오기\n",
    "saved_path = 'C:/Users/andyj/abangers/멀티캠퍼스(데이터분석)/자연어처리'\n",
    "model.load_weights(saved_path)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Normalization\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "class ConvBNRelu(Model):\n",
    "    def __init__(self, filters, kernel_size=3, strides=(1, 1), padding='same'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters, \n",
    "                                  kernel_size=kernel_size, \n",
    "                                  strides=strides, \n",
    "                                  padding=padding, \n",
    "                                  kernel_initializer='glorot_normal'\n",
    "                                  )\n",
    "        self.batchnorm = BatchNormalization()\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        layer = self.conv(input)\n",
    "        layer = self.batchnorm(layer)\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBNRelu(Model):\n",
    "    def __init__(self, units):\n",
    "        super(DenseBNRelu, self).__init__()\n",
    "        self.dense = layers.Dense(units=units, kernel_initializer='glorot_normal')\n",
    "        self.batchnorm = BatchNormalization()\n",
    "        \n",
    "    def call(self, input, training=False):\n",
    "        layer = self.dense(input)\n",
    "        layer = self.batchnorm(layer)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu_3 (ConvBNRelu)  (None, 26, 26, 32)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_bn_relu_4 (ConvBNRelu)  (None, 13, 13, 64)        18752     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_bn_relu_5 (ConvBNRelu)  (None, 7, 7, 128)         74368     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_bn_relu_1 (DenseBNRelu (None, 256)               1606912   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,703,050\n",
      "Trainable params: 1,702,090\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MNISTModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = ConvBNRelu(filters=32, kernel_size= [3, 3], padding='valid')\n",
    "        self.pool1 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv2 = ConvBNRelu(64, (3, 3), padding='same')\n",
    "        self.pool2 = layers.MaxPooling2D(padding='same')\n",
    "        self.conv3 = ConvBNRelu(128, (3, 3), padding='same')\n",
    "        self.conv3_flat = layers.Flatten()\n",
    "        self.dense4 = DenseBNRelu(256)\n",
    "        self.drop4 = layers.Dropout(rate=0.2)\n",
    "        self.dense5 = layers.Dense(units=10, kernel_initializer='glorot_normal', activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.conv3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        net = self.dense5(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "model = MNISTModel()\n",
    "temp_input = layers.Input(shape=(28, 28, 1))\n",
    "model(temp_input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                 batch_size=200,\n",
    "                 callbacks=[cb_checkpoint, cb_early_stopping])\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 784).astype('float32')\n",
    "test_images = test_images.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784, 3), (10000, 784, 3))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3차원으로 만들기\n",
    "train_images = np.dstack([train_images]*3)\n",
    "test_images = np.dstack([test_images]*3)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28, 3)\n",
    "test_images = test_images.reshape(-1, 28, 28, 3)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "train_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in train_images])\n",
    "test_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48, 48))) for im in test_images])\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images/255.\n",
    "test_images = test_images/255.\n",
    "\n",
    "valid_images, test_images, valid_labels, test_labels = train_test_split(test_images, \n",
    "                                                                        test_labels, \n",
    "                                                                        test_size=0.2,\n",
    "                                                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 7s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# imagenet weight\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = {layer.name : layer for layer in vgg_model.layers}\n",
    "x = layer_dict['block2_pool'].output\n",
    "\n",
    "x = ConvBNRelu(filters=64, kernel_size=(3, 3))(x)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = DenseBNRelu(256)(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_bn_relu_6 (ConvBNRelu)  (None, 12, 12, 64)        74048     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_bn_relu_2 (DenseBNRelu (None, 256)               591104    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 927,882\n",
      "Trainable params: 927,242\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_model.layers[:7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "lr_decay = tf.keras.optimizers.schedules.ExponentialDecay(learning_rate, \n",
    "                                                          train_images.shape[0]/batch_size*5, \n",
    "                                                          0.5, \n",
    "                                                          staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)\n",
    "\n",
    "custom_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = '/content/drive/MyDrive/2021 혁신 성장/공유폴더/강의 실습/딥러닝기반 자연어 처리'\n",
    "model_file_path = f'{MODEL_SAVE_FOLDER_PATH}/mnist-{{epoch:d}}-{{val_loss:.5f}}-{{val_accuracy:.5f}}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_file_path,\n",
    "                                monitor='val_accuracy',\n",
    "                                verbose=1,\n",
    "                                save_best_only=True)\n",
    "cb_early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "\n",
    "hist = custom_model.fit(train_images, train_labels, \n",
    "                 validation_data = (valid_images, valid_labels), \n",
    "                 epochs=100,\n",
    "                 batch_size=200,\n",
    "                 callbacks=[cb_checkpoint, cb_early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = 'C:/Users/andyj/abangers/멀티캠퍼스(데이터분석)/자연어처리'\n",
    "model.load_weights(saved_path)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
