{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RNN_Seq2Seq_Train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1eXHvL_Ehrp-Tkf6Cxi5CsxG73iLzh357","authorship_tag":"ABX9TyOusYFw0lwaEPANC6iXULqh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"iaAHd32qn9P4","executionInfo":{"status":"ok","timestamp":1628153035672,"user_tz":-540,"elapsed":1421,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["!cp '/content/drive/MyDrive/Colab Notebooks/NLP/preprocess.py' ."],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8T_96wi-oukK","executionInfo":{"status":"ok","timestamp":1628153045021,"user_tz":-540,"elapsed":9356,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["!cp -r '/content/drive/MyDrive/Colab Notebooks/NLP/data_in' ."],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xo8GmRW2pJwt","executionInfo":{"status":"ok","timestamp":1628153052035,"user_tz":-540,"elapsed":7023,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}},"outputId":"f0c0c294-7903-49ba-9c00-d2acfe537eab"},"source":["!pip install konlpy"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 35.5 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XjB68gMQox1F","executionInfo":{"status":"ok","timestamp":1628153053855,"user_tz":-540,"elapsed":1827,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","\n","from preprocess import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"met4QxQspYId","executionInfo":{"status":"ok","timestamp":1628153053857,"user_tz":-540,"elapsed":22,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["# 시각화 함수\n","def plot_graphs(history, string):\n","    plt.plot(history.history[string])\n","    plt.plot(history.history['val_' + string])\n","    plt.xlabel('Epochs')\n","    plt.ylabel(string)\n","    plt.legend([string, 'val_' + string])\n","    plt.show()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0h1zVe5pwLJ","executionInfo":{"status":"ok","timestamp":1628153053858,"user_tz":-540,"elapsed":21,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["DATA_IN_PATH = './data_in/'\n","DATA_OUT_PATH = './data_out/'\n","TRAIN_INPUTS = 'train_inputs.npy'\n","TRAIN_OUTPUTS = 'train_outputs.npy'\n","TRAIN_TARGETS = 'train_targets.npy'\n","DATA_CONFIG = 'data_configs.json'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbEkP-jjp6AW","executionInfo":{"status":"ok","timestamp":1628153053859,"user_tz":-540,"elapsed":20,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["SEED_NUM = 42\n","tf.random.set_seed(SEED_NUM)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2akoXp_p_KN","executionInfo":{"status":"ok","timestamp":1628153053861,"user_tz":-540,"elapsed":21,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n","index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS, 'rb'))\n","index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS, 'rb'))\n","prepro_config = json.load(open(DATA_IN_PATH + DATA_CONFIG, 'r'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"if-pBV9dqckE","executionInfo":{"status":"ok","timestamp":1628153053862,"user_tz":-540,"elapsed":21,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}},"outputId":"e6055501-137a-47aa-b284-c183d490ffb2"},"source":["len(index_inputs), len(index_outputs), len(index_targets)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11823, 11823, 11823)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"MYBTq1-Kqh4_","executionInfo":{"status":"ok","timestamp":1628153054414,"user_tz":-540,"elapsed":17,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["MODEL_NAME = 'seq2seq_kor'\n","BATCH_SIZE = 24\n","MAX_SEQUENCE = 25\n","EPOCH = 30\n","UNITS = 1024\n","EMBEDDING_DIM = 256\n","VALIDATION_SPLIT = 0.1\n","\n","word2idx = prepro_config['word2idx']\n","idx2word = prepro_config['idx2word']\n","sos_idx = prepro_config['sos_symbol']\n","eos_idx = prepro_config['eos_symbol']\n","vocab_size = prepro_config['vocab_size']"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"25kpEveZsm89","executionInfo":{"status":"ok","timestamp":1628153054415,"user_tz":-540,"elapsed":16,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n","        super(Encoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.enc_units = enc_units\n","        self.embedding_dim = embedding_dim\n","        self.vocab_size = vocab_size\n","\n","        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences = True , return_state = True, recurrent_initializer='glorot_uniform')\n","\n","\n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        output, state = self.gru(x, initial_state=hidden)\n","        return output, state\n","\n","    def initial_hidden_state(self, input):\n","        return tf.zeros((tf.shape(input)[0], self.enc_units))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"En6_v2qe3FdC","executionInfo":{"status":"ok","timestamp":1628153054416,"user_tz":-540,"elapsed":16,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super(BahdanauAttention, self).__init__()\n","        self.W1 = tf.keras.layers.Dense(units)\n","        self.W2 = tf.keras.layers.Dense(units)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    def call(self, query, values):\n","        # values = h\n","        hidden_with_time_axis = tf.expand_dims(query, 1)\n","\n","        score = self.V(tf.nn.tanh(\n","            self.W1(values) + self.W2(hidden_with_time_axis)\n","        ))\n","        \n","        # 서로간의 유사도\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","\n","        context_vector = attention_weights * values\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector, attention_weights"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrbuxU_WKwju","executionInfo":{"status":"ok","timestamp":1628153054417,"user_tz":-540,"elapsed":16,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n","        super(Decoder, self).__init__()\n","\n","        self.batch_size = batch_size\n","        self.dec_units = dec_units\n","        self.embedding_dim = embedding_dim\n","        self.vocab_size = vocab_size\n","\n","        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n","        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n","\n","        # 단어가 하나씩 뽑히는 output 설정 (fully connected)\n","        self.fc = tf.keras.layers.Dense(vocab_size)\n","        \n","        self.attention = BahdanauAttention(self.dec_units)\n","\n","    def call(self, x, hidden, enc_output):\n","        context_vector, attention_weight = self.attention(hidden, enc_output)\n","\n","        x = self.embedding(x)\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        output, state = self.gru(x)\n","        output = tf.reshape(output, (-1, output.shape[2]))\n","\n","        x = self.fc(output)\n","\n","        return x, state, attention_weight"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kA7adWUS1-m","executionInfo":{"status":"ok","timestamp":1628153059938,"user_tz":-540,"elapsed":5536,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","\n","# from_logits=True는 안에서 softmax로 안하고 logit으로 반환\n","loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeSttSxyTdDX","executionInfo":{"status":"ok","timestamp":1628153059939,"user_tz":-540,"elapsed":17,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["# loss & accuracy에서 PAD값 제외하기 위한 함수\n","\n","def loss(real, pred):\n","    # logical_not: True => False\n","    mask = tf.math.logical_not(tf.math.equal(real, 0)) # PAD가 있는 쪽 (True)을 False로 바꿈\n","    loss_ = loss_fn(real, pred)\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    return tf.reduce_mean(loss_)\n","\n","def accuracy(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n","    pred *= mask\n","    acc = train_accuracy(real, pred)\n","\n","    return tf.reduce_mean(acc) "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcV6uBwJVV2J","executionInfo":{"status":"ok","timestamp":1628153059940,"user_tz":-540,"elapsed":15,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["# Model 생성\n","class Seq2Seq(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_size, end_token_id = EOS_INDEX ):\n","        super(Seq2Seq, self).__init__()\n","        self.end_token_id = end_token_id\n","        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_size)\n","        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_size)\n","\n","    def call(self, x):\n","        input, target = x\n","\n","        enc_hidden = self.encoder.initial_hidden_state(input)\n","        enc_output, enc_hidden = self.encoder(input, enc_hidden)\n","\n","        dec_hidden = enc_hidden\n","\n","        predict_tokens = []\n","\n","        for t in range(target.shape[1]):\n","            dec_input = tf.dtypes.cast(tf.expand_dims(target[:,t], 1), tf.float32)\n","            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n","            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n","\n","        return tf.stack(predict_tokens, axis=1)\n","\n","    \n","    def inference(self, x):\n","        input = x\n","\n","        enc_hidden = self.encoder.initial_hidden_state(input)\n","        enc_output, enc_hidden = self.encoder(input, enc_hidden)\n","\n","        dec_hidden = enc_hidden\n","\n","        dec_input = tf.expand_dims([word2idx[sos_idx]], 1)\n","\n","        predict_tokens = []\n","        for t in range(MAX_SEQUENCE):\n","            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n","            predict_token = tf.argmax(predictions)\n","\n","            if predict_token == self.end_token_id:\n","                break\n","            \n","            predict_tokens.append(predict_token)\n","            dec_input = tf.dtype.cast(tf.expand_dim([predict_token], 0), tf.float32)\n","\n","        return tf.stack(predict_tokens, axis=0).numpy()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-tUp4G95d-Mf","executionInfo":{"status":"ok","timestamp":1628153059941,"user_tz":-540,"elapsed":13,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["model = Seq2Seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE)\n","model.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_PazScT1e8Q7","executionInfo":{"elapsed":2962150,"status":"ok","timestamp":1628061807240,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"},"user_tz":-540},"outputId":"6fd02f02-6019-493a-f84f-26b935a773d3"},"source":["# 학습\n","PATH = DATA_OUT_PATH + MODEL_NAME\n","if not (os.path.isdir(PATH)):\n","    os.makedirs(os.path.join(PATH))\n","\n","checkpoint_path = DATA_OUT_PATH + MODEL_NAME + \"/weights.hdf5\"\n","\n","cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n","earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n","\n","history = model.fit([index_inputs, index_outputs], index_targets, batch_size=BATCH_SIZE, epochs=EPOCH, \n","                    validation_split=VALIDATION_SPLIT, callbacks=[earlystop_callback, cp_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0149 - accuracy: 0.9297 - val_loss: 2.9156 - val_accuracy: 0.9306\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.93063, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 2/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0146 - accuracy: 0.9315 - val_loss: 2.9463 - val_accuracy: 0.9324\n","\n","Epoch 00002: val_accuracy improved from 0.93063 to 0.93239, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 3/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0148 - accuracy: 0.9332 - val_loss: 3.0142 - val_accuracy: 0.9340\n","\n","Epoch 00003: val_accuracy improved from 0.93239 to 0.93403, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 4/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0156 - accuracy: 0.9348 - val_loss: 2.9781 - val_accuracy: 0.9355\n","\n","Epoch 00004: val_accuracy improved from 0.93403 to 0.93553, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 5/30\n","444/444 [==============================] - 97s 219ms/step - loss: 0.0148 - accuracy: 0.9363 - val_loss: 3.0723 - val_accuracy: 0.9369\n","\n","Epoch 00005: val_accuracy improved from 0.93553 to 0.93694, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 6/30\n","444/444 [==============================] - 97s 220ms/step - loss: 0.0131 - accuracy: 0.9376 - val_loss: 3.0543 - val_accuracy: 0.9383\n","\n","Epoch 00006: val_accuracy improved from 0.93694 to 0.93825, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 7/30\n","444/444 [==============================] - 97s 219ms/step - loss: 0.0109 - accuracy: 0.9389 - val_loss: 3.0860 - val_accuracy: 0.9395\n","\n","Epoch 00007: val_accuracy improved from 0.93825 to 0.93951, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 8/30\n","444/444 [==============================] - 97s 219ms/step - loss: 0.0103 - accuracy: 0.9401 - val_loss: 3.0945 - val_accuracy: 0.9407\n","\n","Epoch 00008: val_accuracy improved from 0.93951 to 0.94069, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 9/30\n","444/444 [==============================] - 97s 219ms/step - loss: 0.0081 - accuracy: 0.9413 - val_loss: 3.1107 - val_accuracy: 0.9418\n","\n","Epoch 00009: val_accuracy improved from 0.94069 to 0.94181, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 10/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0095 - accuracy: 0.9424 - val_loss: 3.1431 - val_accuracy: 0.9429\n","\n","Epoch 00010: val_accuracy improved from 0.94181 to 0.94286, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 11/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0137 - accuracy: 0.9434 - val_loss: 3.1493 - val_accuracy: 0.9438\n","\n","Epoch 00011: val_accuracy improved from 0.94286 to 0.94381, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 12/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0161 - accuracy: 0.9443 - val_loss: 3.1791 - val_accuracy: 0.9447\n","\n","Epoch 00012: val_accuracy improved from 0.94381 to 0.94468, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 13/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0126 - accuracy: 0.9451 - val_loss: 3.1887 - val_accuracy: 0.9455\n","\n","Epoch 00013: val_accuracy improved from 0.94468 to 0.94554, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 14/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0088 - accuracy: 0.9460 - val_loss: 3.2034 - val_accuracy: 0.9464\n","\n","Epoch 00014: val_accuracy improved from 0.94554 to 0.94638, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 15/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0081 - accuracy: 0.9468 - val_loss: 3.2292 - val_accuracy: 0.9472\n","\n","Epoch 00015: val_accuracy improved from 0.94638 to 0.94717, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 16/30\n","444/444 [==============================] - 96s 216ms/step - loss: 0.0083 - accuracy: 0.9476 - val_loss: 3.2352 - val_accuracy: 0.9479\n","\n","Epoch 00016: val_accuracy improved from 0.94717 to 0.94793, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 17/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0085 - accuracy: 0.9483 - val_loss: 3.2802 - val_accuracy: 0.9486\n","\n","Epoch 00017: val_accuracy improved from 0.94793 to 0.94865, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 18/30\n","444/444 [==============================] - 96s 216ms/step - loss: 0.0095 - accuracy: 0.9490 - val_loss: 3.2767 - val_accuracy: 0.9493\n","\n","Epoch 00018: val_accuracy improved from 0.94865 to 0.94932, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 19/30\n","444/444 [==============================] - 96s 216ms/step - loss: 0.0107 - accuracy: 0.9497 - val_loss: 3.2395 - val_accuracy: 0.9500\n","\n","Epoch 00019: val_accuracy improved from 0.94932 to 0.94996, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 20/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0105 - accuracy: 0.9503 - val_loss: 3.2849 - val_accuracy: 0.9506\n","\n","Epoch 00020: val_accuracy improved from 0.94996 to 0.95057, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 21/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0087 - accuracy: 0.9509 - val_loss: 3.3395 - val_accuracy: 0.9512\n","\n","Epoch 00021: val_accuracy improved from 0.95057 to 0.95116, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 22/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0090 - accuracy: 0.9515 - val_loss: 3.3343 - val_accuracy: 0.9517\n","\n","Epoch 00022: val_accuracy improved from 0.95116 to 0.95172, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 23/30\n","444/444 [==============================] - 96s 216ms/step - loss: 0.0091 - accuracy: 0.9520 - val_loss: 3.3174 - val_accuracy: 0.9523\n","\n","Epoch 00023: val_accuracy improved from 0.95172 to 0.95225, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 24/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0081 - accuracy: 0.9525 - val_loss: 3.3696 - val_accuracy: 0.9528\n","\n","Epoch 00024: val_accuracy improved from 0.95225 to 0.95277, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 25/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0069 - accuracy: 0.9530 - val_loss: 3.3426 - val_accuracy: 0.9533\n","\n","Epoch 00025: val_accuracy improved from 0.95277 to 0.95328, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 26/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0065 - accuracy: 0.9535 - val_loss: 3.3638 - val_accuracy: 0.9538\n","\n","Epoch 00026: val_accuracy improved from 0.95328 to 0.95376, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 27/30\n","444/444 [==============================] - 97s 218ms/step - loss: 0.0086 - accuracy: 0.9540 - val_loss: 3.4204 - val_accuracy: 0.9542\n","\n","Epoch 00027: val_accuracy improved from 0.95376 to 0.95422, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 28/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0089 - accuracy: 0.9544 - val_loss: 3.4023 - val_accuracy: 0.9547\n","\n","Epoch 00028: val_accuracy improved from 0.95422 to 0.95466, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 29/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0094 - accuracy: 0.9549 - val_loss: 3.4075 - val_accuracy: 0.9551\n","\n","Epoch 00029: val_accuracy improved from 0.95466 to 0.95508, saving model to ./data_out/seq2seq_kor/weights.hdf5\n","Epoch 30/30\n","444/444 [==============================] - 96s 217ms/step - loss: 0.0086 - accuracy: 0.9553 - val_loss: 3.4378 - val_accuracy: 0.9555\n","\n","Epoch 00030: val_accuracy improved from 0.95508 to 0.95548, saving model to ./data_out/seq2seq_kor/weights.hdf5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TLX7qr8CP9v7","executionInfo":{"status":"ok","timestamp":1628153372279,"user_tz":-540,"elapsed":7,"user":{"displayName":"KooHong Jung","photoUrl":"","userId":"09809669667891454437"}}},"source":["model.load_weights(os.path.join(DATA_OUT_PATH + MODEL_NAME + \"/weights.hdf5\"))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_2WORw4ggHU"},"source":["query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n","\n","test_index_inputs, _ = enc_processing([query], word2idx)\n","predict_tokens = model.inference(test_index_inputs)\n","print(predict_tokens)\n","\n","print(\" \".join([idx2word[str(t)] for  t in predict_tokens]))"],"execution_count":null,"outputs":[]}]}