{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN_Seq2Seq_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaAHd32qn9P4"
      },
      "source": [
        "!cp '/content/drive/MyDrive/Colab Notebooks/NLP/preprocess.py' ."
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T_96wi-oukK"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/Colab Notebooks/NLP/data_in' ."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bdI2digCgJC"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/Colab Notebooks/NLP/data_out' ."
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo8GmRW2pJwt",
        "outputId": "316535f3-f6af-412f-b496-bb79a8ac4842"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 91.1 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjB68gMQox1F"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from preprocess import *"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "met4QxQspYId"
      },
      "source": [
        "# 시각화 함수\n",
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_' + string])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_' + string])\n",
        "    plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0h1zVe5pwLJ"
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "TRAIN_INPUTS = 'train_inputs.npy'\n",
        "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
        "TRAIN_TARGETS = 'train_targets.npy'\n",
        "DATA_CONFIG = 'data_configs.json'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbEkP-jjp6AW"
      },
      "source": [
        "SEED_NUM = 42\n",
        "tf.random.set_seed(SEED_NUM)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2akoXp_p_KN"
      },
      "source": [
        "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
        "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS, 'rb'))\n",
        "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS, 'rb'))\n",
        "prepro_config = json.load(open(DATA_IN_PATH + DATA_CONFIG, 'r'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if-pBV9dqckE",
        "outputId": "af80d449-1cd1-41f4-ba2a-ce1eaff3921e"
      },
      "source": [
        "len(index_inputs), len(index_outputs), len(index_targets)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11823, 11823, 11823)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYBTq1-Kqh4_"
      },
      "source": [
        "MODEL_NAME = 'seq2seq_kor'\n",
        "BATCH_SIZE = 24\n",
        "MAX_SEQUENCE = 25\n",
        "EPOCH = 30\n",
        "UNITS = 1024\n",
        "EMBEDDING_DIM = 256\n",
        "VALIDATION_SPLIT = 0.1\n",
        "\n",
        "word2idx = prepro_config['word2idx']\n",
        "idx2word = prepro_config['idx2word']\n",
        "sos_idx = prepro_config['sos_symbol']\n",
        "eos_idx = prepro_config['eos_symbol']\n",
        "vocab_size = prepro_config['vocab_size']"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25kpEveZsm89"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences = True , return_state = True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initial_hidden_state(self, input):\n",
        "        return tf.zeros((tf.shape(input)[0], self.enc_units))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En6_v2qe3FdC"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # values = h\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(values) + self.W2(hidden_with_time_axis)\n",
        "        ))\n",
        "        \n",
        "        # 서로간의 유사도\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrbuxU_WKwju"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # 단어가 하나씩 뽑히는 output 설정 (fully connected)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weight = self.attention(hidden, enc_output)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weight"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kA7adWUS1-m"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# from_logits=True는 안에서 softmax로 안하고 logit으로 반환\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSttSxyTdDX"
      },
      "source": [
        "# loss & accuracy에서 PAD값 제외하기 위한 함수\n",
        "\n",
        "def loss(real, pred):\n",
        "    # logical_not: True => False\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # PAD가 있는 쪽 (True)을 False로 바꿈\n",
        "    loss_ = loss_fn(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask\n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc) "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcV6uBwJVV2J"
      },
      "source": [
        "# Model 생성\n",
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_size, end_token_id = EOS_INDEX ):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.end_token_id = end_token_id\n",
        "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_size)\n",
        "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        input, target = x\n",
        "\n",
        "        enc_hidden = self.encoder.initial_hidden_state(input)\n",
        "        enc_output, enc_hidden = self.encoder(input, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        predict_tokens = []\n",
        "\n",
        "        for t in range(target.shape[1]):\n",
        "            dec_input = tf.dtypes.cast(tf.expand_dims(target[:,t], 1), tf.float32)\n",
        "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
        "\n",
        "        return tf.stack(predict_tokens, axis=1)\n",
        "\n",
        "    \n",
        "    def inference(self, x):\n",
        "        input = x\n",
        "\n",
        "        enc_hidden = self.encoder.initial_hidden_state(input)\n",
        "        enc_output, enc_hidden = self.encoder(input, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([word2idx[sos_idx]], 1)\n",
        "\n",
        "        predict_tokens = []\n",
        "        for t in range(MAX_SEQUENCE):\n",
        "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "            predict_token = tf.argmax(predictions[0])\n",
        "\n",
        "            if predict_token == self.end_token_id:\n",
        "                break\n",
        "            \n",
        "            predict_tokens.append(predict_token)\n",
        "            dec_input = tf.cast(tf.expand_dims([predict_token], 0), tf.float32)\n",
        "\n",
        "        return tf.stack(predict_tokens, axis=0).numpy()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tUp4G95d-Mf"
      },
      "source": [
        "model = Seq2Seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PazScT1e8Q7",
        "outputId": "b327db54-f4f7-4181-9399-47c2e2f8a9a5"
      },
      "source": [
        "# 학습\n",
        "PATH = DATA_OUT_PATH + MODEL_NAME\n",
        "if not (os.path.isdir(PATH)):\n",
        "    os.makedirs(os.path.join(PATH))\n",
        "\n",
        "checkpoint_path = DATA_OUT_PATH + MODEL_NAME + \"/weights.h5\"\n",
        "\n",
        "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
        "\n",
        "history = model.fit([index_inputs, index_outputs], index_targets, batch_size=BATCH_SIZE, epochs=EPOCH, \n",
        "                    validation_split=VALIDATION_SPLIT, callbacks=[earlystop_callback, cp_callback])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "444/444 [==============================] - 141s 238ms/step - loss: 1.4938 - accuracy: 0.7922 - val_loss: 1.5813 - val_accuracy: 0.7943\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.79432, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 2/30\n",
            "444/444 [==============================] - 98s 221ms/step - loss: 1.1783 - accuracy: 0.8008 - val_loss: 1.4993 - val_accuracy: 0.8061\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.79432 to 0.80613, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 3/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.9842 - accuracy: 0.8113 - val_loss: 1.5254 - val_accuracy: 0.8152\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.80613 to 0.81522, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 4/30\n",
            "444/444 [==============================] - 98s 221ms/step - loss: 0.8180 - accuracy: 0.8198 - val_loss: 1.5870 - val_accuracy: 0.8236\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.81522 to 0.82364, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 5/30\n",
            "444/444 [==============================] - 98s 221ms/step - loss: 0.6736 - accuracy: 0.8284 - val_loss: 1.7037 - val_accuracy: 0.8324\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.82364 to 0.83237, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 6/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.5525 - accuracy: 0.8374 - val_loss: 1.8175 - val_accuracy: 0.8414\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.83237 to 0.84142, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 7/30\n",
            "444/444 [==============================] - 98s 221ms/step - loss: 0.4540 - accuracy: 0.8461 - val_loss: 1.9278 - val_accuracy: 0.8502\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.84142 to 0.85018, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 8/30\n",
            "444/444 [==============================] - 99s 223ms/step - loss: 0.3557 - accuracy: 0.8546 - val_loss: 2.0056 - val_accuracy: 0.8585\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.85018 to 0.85848, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 9/30\n",
            "444/444 [==============================] - 98s 220ms/step - loss: 0.2545 - accuracy: 0.8628 - val_loss: 2.1297 - val_accuracy: 0.8665\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.85848 to 0.86651, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 10/30\n",
            "444/444 [==============================] - 98s 221ms/step - loss: 0.1659 - accuracy: 0.8707 - val_loss: 2.2288 - val_accuracy: 0.8745\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.86651 to 0.87447, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 11/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.1024 - accuracy: 0.8785 - val_loss: 2.3412 - val_accuracy: 0.8821\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.87447 to 0.88210, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 12/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0637 - accuracy: 0.8858 - val_loss: 2.4131 - val_accuracy: 0.8891\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.88210 to 0.88913, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 13/30\n",
            "444/444 [==============================] - 97s 220ms/step - loss: 0.0412 - accuracy: 0.8924 - val_loss: 2.4789 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.88913 to 0.89546, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 14/30\n",
            "444/444 [==============================] - 97s 218ms/step - loss: 0.0301 - accuracy: 0.8984 - val_loss: 2.5317 - val_accuracy: 0.9011\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.89546 to 0.90106, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 15/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0234 - accuracy: 0.9036 - val_loss: 2.5918 - val_accuracy: 0.9060\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.90106 to 0.90600, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 16/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0213 - accuracy: 0.9082 - val_loss: 2.6394 - val_accuracy: 0.9103\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.90600 to 0.91034, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 17/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0185 - accuracy: 0.9123 - val_loss: 2.6751 - val_accuracy: 0.9142\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.91034 to 0.91420, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 18/30\n",
            "444/444 [==============================] - 98s 220ms/step - loss: 0.0203 - accuracy: 0.9160 - val_loss: 2.7287 - val_accuracy: 0.9176\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.91420 to 0.91760, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 19/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0225 - accuracy: 0.9192 - val_loss: 2.7490 - val_accuracy: 0.9206\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.91760 to 0.92061, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 20/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0245 - accuracy: 0.9220 - val_loss: 2.7955 - val_accuracy: 0.9233\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.92061 to 0.92328, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 21/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0215 - accuracy: 0.9246 - val_loss: 2.8004 - val_accuracy: 0.9257\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92328 to 0.92574, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 22/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0163 - accuracy: 0.9269 - val_loss: 2.8190 - val_accuracy: 0.9280\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.92574 to 0.92802, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 23/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0134 - accuracy: 0.9291 - val_loss: 2.8648 - val_accuracy: 0.9301\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92802 to 0.93013, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 24/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0121 - accuracy: 0.9311 - val_loss: 2.9225 - val_accuracy: 0.9321\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93013 to 0.93208, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 25/30\n",
            "444/444 [==============================] - 97s 219ms/step - loss: 0.0124 - accuracy: 0.9330 - val_loss: 2.9540 - val_accuracy: 0.9339\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.93208 to 0.93386, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 26/30\n",
            "444/444 [==============================] - 98s 220ms/step - loss: 0.0141 - accuracy: 0.9347 - val_loss: 2.9700 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00026: val_accuracy improved from 0.93386 to 0.93550, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 27/30\n",
            "444/444 [==============================] - 97s 218ms/step - loss: 0.0155 - accuracy: 0.9363 - val_loss: 2.9864 - val_accuracy: 0.9370\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.93550 to 0.93699, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 28/30\n",
            "444/444 [==============================] - 98s 220ms/step - loss: 0.0154 - accuracy: 0.9377 - val_loss: 2.9629 - val_accuracy: 0.9384\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.93699 to 0.93838, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 29/30\n",
            "444/444 [==============================] - 97s 220ms/step - loss: 0.0132 - accuracy: 0.9391 - val_loss: 3.0191 - val_accuracy: 0.9397\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93838 to 0.93969, saving model to ./data_out/seq2seq_kor/weights.h5\n",
            "Epoch 30/30\n",
            "444/444 [==============================] - 97s 218ms/step - loss: 0.0120 - accuracy: 0.9403 - val_loss: 3.0270 - val_accuracy: 0.9409\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.93969 to 0.94093, saving model to ./data_out/seq2seq_kor/weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLX7qr8CP9v7"
      },
      "source": [
        "model.load_weights(os.path.join(DATA_OUT_PATH + MODEL_NAME + \"/weights.h5\"))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_2WORw4ggHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce40c753-a4fa-43fd-ae27-831fdc3cbf5a"
      },
      "source": [
        "# 챗봇 기능 확인\n",
        "query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
        "\n",
        "test_index_inputs, _ = enc_processing([query], word2idx)\n",
        "predict_tokens = model.inference(test_index_inputs)\n",
        "print(predict_tokens)\n",
        "\n",
        "print(\" \".join([idx2word[str(t)] for  t in predict_tokens]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1599   275 11789  3500   594  4541  9502]\n",
            "평소 에 필요했던 게 좋을 것 같아요\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}